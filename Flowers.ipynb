{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "Flowers_ver2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5D_Yrm2Ep0po"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCV5z5_5qJNs"
      },
      "source": [
        "%cd '/content/gdrive/MyDrive/Colab Notebooks'\n",
        "%ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QchnfPhfqrXz"
      },
      "source": [
        "!unzip 'flowers-recognition.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UM644l_GDlpo"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from warnings import filterwarnings\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score, roc_curve\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization,MaxPooling2D,BatchNormalization,\\\n",
        "                        Permute, TimeDistributed, Bidirectional,GRU, Activation\n",
        "from keras import models\n",
        "from keras import layers\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import os.path\n",
        "from pathlib import Path\n",
        "import cv2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import regularizers\n",
        "from keras.optimizers import RMSprop,Adam\n",
        "import glob\n",
        "from PIL import Image\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.preprocessing import image\n",
        "from keras.layers import SimpleRNN\n",
        "from keras.layers import LSTM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1MNlu1pJTX8"
      },
      "source": [
        "Flowers_Path = Path('/content/gdrive/MyDrive/Colab Notebooks/flowers')\n",
        "Flowers_Path = list(Flowers_Path.glob(r\"*/*.jpg\"))\n",
        "Flowers_Labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1],Flowers_Path))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKftNOhiKVA6"
      },
      "source": [
        "Flowers_Path_Series = pd.Series(Flowers_Path,name=\"PATH\").astype(str)\n",
        "Flowers_Labels_Series = pd.Series(Flowers_Labels,name=\"CATEGORY\")\n",
        "\n",
        "Flowers_Data= pd.concat([Flowers_Path_Series,Flowers_Labels_Series],axis=1)\n",
        "Flowers_Data = Flowers_Data.sample(frac=1).reset_index(drop=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yX0Mc2_rZkcL"
      },
      "source": [
        "plt.figure(figsize=(8,8))\n",
        "Flowers_percent=Flowers_Data.groupby('CATEGORY').PATH.count()/len(Flowers_Data)\n",
        "\n",
        "print(Flowers_percent)\n",
        "\n",
        "Flowers_percent.plot.bar()\n",
        "plt.title(\"Percent of images in each class\")\n",
        "plt.ylabel('Percent(%)')\n",
        "plt.title('Number of images in each class')\n",
        "\n",
        "plt.savefig('Flower percents.png')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAICW3cIQby6"
      },
      "source": [
        "#I/ Data DataGenerator:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCMBTfI7K2Rx"
      },
      "source": [
        "Train_Generator = ImageDataGenerator(rescale=1./255,\n",
        "                                    zoom_range=0.2,\n",
        "                                    rotation_range=40,\n",
        "                                    shear_range=0.2,\n",
        "                                     channel_shift_range=0.2,\n",
        "                                     fill_mode=\"nearest\",\n",
        "                                    horizontal_flip=True)\n",
        "\n",
        "Test_Generator = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCz_WcKDLU4S"
      },
      "source": [
        "Train_Data,Test_Data = train_test_split(Flowers_Data,train_size=0.8,random_state=123,shuffle=True)\n",
        "Test_Data, Val_Data  = train_test_split(Test_Data,train_size=0.5,random_state=123,shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGktGcjcLxKk"
      },
      "source": [
        "IMG_SIZE = (224, 224)\n",
        "INP_SHAPE = (*IMG_SIZE, 3)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "images_train = Train_Generator.flow_from_dataframe(dataframe=Train_Data,\n",
        "                                                   x_col=\"PATH\",\n",
        "                                                   y_col=\"CATEGORY\",\n",
        "                                                   color_mode=\"rgb\",\n",
        "                                                   class_mode=\"categorical\",\n",
        "                                                   batch_size=32,\n",
        "                                                   target_size=IMG_SIZE)\n",
        "\n",
        "images_val = Test_Generator.flow_from_dataframe(dataframe=Val_Data,\n",
        "                                                   x_col=\"PATH\",\n",
        "                                                   y_col=\"CATEGORY\",\n",
        "                                                   color_mode=\"rgb\",\n",
        "                                                   class_mode=\"categorical\",\n",
        "                                                   batch_size=32,\n",
        "                                                   target_size=IMG_SIZE)\n",
        "\n",
        "images_test = Test_Generator.flow_from_dataframe(dataframe=Test_Data,\n",
        "                                                   x_col=\"PATH\",\n",
        "                                                   y_col=\"CATEGORY\",\n",
        "                                                   color_mode=\"rgb\",\n",
        "                                                   class_mode=\"categorical\",\n",
        "                                                   batch_size=32,\n",
        "                                                   target_size=IMG_SIZE)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rbEHjb0Qwlz"
      },
      "source": [
        "#II/ Training model:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9EbnKjp4o0I"
      },
      "source": [
        "##1/ CNN:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCLlLrI12_jT"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same',activation ='relu', input_shape = INP_SHAPE))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(filters =96, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(filters = 96, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(5, activation = \"softmax\"))\n",
        "\n",
        "model.compile(optimizer=Adam(lr=0.001),loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjjnJnQo4w9q"
      },
      "source": [
        "checkpoint_path =\"CNN.h5\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "# Create a callback that saves the model's weights every 10 epochs\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_path, \n",
        "    verbose=1, \n",
        "    save_weights_only=False,\n",
        "    save_freq=\"epoch\",\n",
        "    save_best_only=True)\n",
        "\n",
        "model.save_weights(checkpoint_path.format(epoch=0))\n",
        "\n",
        "model.fit(images_train, validation_data=images_val,batch_size = BATCH_SIZE,epochs=30,callbacks=[cp_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTetpchgUhjz"
      },
      "source": [
        "##2.MobileNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-Y52XN70-Hu"
      },
      "source": [
        "from tensorflow.keras.models import load_model, Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.applications import MobileNet\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "\n",
        "# MobileNet\n",
        "model=Sequential()\n",
        "model.add(MobileNet(input_shape=(224, 224, 3), include_top = False,dropout=0.01, weights = 'imagenet'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, input_dim=64,\n",
        "                kernel_regularizer=regularizers.l2(0.01),\n",
        "                activity_regularizer=regularizers.l2(0.01)))\n",
        "\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(5, activation=\"softmax\"))\n",
        "'''\n",
        "model = Sequential([base_network, \n",
        "                    flat,\n",
        "                    den])\n",
        "'''\n",
        "model.compile(loss='categorical_crossentropy', optimizer=\"adam\",metrics=[\"accuracy\"])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpDM8NYjAOMV"
      },
      "source": [
        "# Frozen EfficientNet network\n",
        "for layer in model.layers[:1]:\n",
        "  layer.trainable = False\n",
        "\n",
        "for layer in model.layers:\n",
        "  print('Layer: {} ; Trainable: {}'.format(layer, layer.trainable))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEvd2ed1FqZF"
      },
      "source": [
        "# Include the epoch in the file name (uses `str.format`)\n",
        "#checkpoint_path = \"cp-{epoch:04d}-{val_accuracy}.ckpt\"\n",
        "checkpoint_path =\"MobileNet.h5\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "# Create a callback that saves the model's weights every 10 epochs\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_path, \n",
        "    verbose=1, \n",
        "    save_weights_only=False,\n",
        "    save_freq=\"epoch\",\n",
        "    save_best_only=True)\n",
        "\n",
        "# Save the weights using the `checkpoint_path` format\n",
        "'''\n",
        "period=N:int: Save weights, every N-epochs.\n",
        "save_freq=\"epoch\"||N:int: Save weights, each epoch || every N-batches. \n",
        "save_best_only=True: Save weights of only best model.\n",
        "\n",
        "'''\n",
        "# Train the model with the new callback\n",
        "model.fit(images_train, validation_data=images_val,batch_size = BATCH_SIZE,epochs=20,callbacks=[cp_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ro3gcT-LGU9d"
      },
      "source": [
        "# Defrost EfficientNet network\n",
        "#model=load_model('MobileNet_ver2.h5')\n",
        "for layer in model.layers[:1]:\n",
        "  layer.trainable = True\n",
        "\n",
        "for layer in model.layers:\n",
        "  print('Layer: {} ; Trainable: {}'.format(layer, layer.trainable))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acNVUcOoGU9h"
      },
      "source": [
        "model.fit(images_train, validation_data=images_val,epochs=10,callbacks=[cp_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqmNaXfaUt5H"
      },
      "source": [
        "# III/ Evaluating Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUh83WlT5rVy"
      },
      "source": [
        "model=load_model('MobileNet.h5')\n",
        "model.evaluate(images_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2KjQanz6RJ1"
      },
      "source": [
        "model=load_model('CNN_ver2.h5')\n",
        "model.evaluate(images_test)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}